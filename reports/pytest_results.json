{"created": 1767624332.8005195, "duration": 49.43591856956482, "exitcode": 0, "root": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo", "environment": {}, "summary": {"passed": 31, "skipped": 1, "total": 32, "collected": 32}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Dir"}]}, {"nodeid": "tests/models", "outcome": "passed", "result": []}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_on_known_image", "type": "Function", "lineno": 27}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_result_format", "type": "Function", "lineno": 42}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_confidence_threshold_works", "type": "Function", "lineno": 58}]}, {"nodeid": "tests/test_functional.py::TestDatasetDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_normal_dataset", "type": "Function", "lineno": 84}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_edge_cases_dataset", "type": "Function", "lineno": 107}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_inference_time_reasonable", "type": "Function", "lineno": 127}]}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_detect_by_category", "type": "Function", "lineno": 153}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_compare_normal_vs_edge_cases", "type": "Function", "lineno": 172}]}, {"nodeid": "tests/test_functional.py::TestResultsSaving", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_creates_file", "type": "Function", "lineno": 207}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_json_format", "type": "Function", "lineno": 220}]}, {"nodeid": "tests/test_functional.py", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestDatasetDetection", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestResultsSaving", "type": "Class"}]}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_cold_start_latency", "type": "Function", "lineno": 27}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_warm_inference_latency", "type": "Function", "lineno": 41}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_latency_variance", "type": "Function", "lineno": 67}]}, {"nodeid": "tests/test_performance.py::TestResourceUsage", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestResourceUsage::test_cpu_usage_during_inference", "type": "Function", "lineno": 95}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_memory_usage", "type": "Function", "lineno": 129}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_gpu_availability_check", "type": "Function", "lineno": 149}]}, {"nodeid": "tests/test_performance.py::TestFPSRealTime", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestFPSRealTime::test_sustained_fps", "type": "Function", "lineno": 173}, {"nodeid": "tests/test_performance.py::TestFPSRealTime::test_batch_vs_single_inference", "type": "Function", "lineno": 192}]}, {"nodeid": "tests/test_performance.py::TestModelBenchmarking", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestModelBenchmarking::test_yolov8_model_variants", "type": "Function", "lineno": 222}]}, {"nodeid": "tests/test_performance.py::TestSystemInfo", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestSystemInfo::test_collect_system_info", "type": "Function", "lineno": 259}]}, {"nodeid": "tests/test_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestLatencyPerformance", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestResourceUsage", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestFPSRealTime", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestModelBenchmarking", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestSystemInfo", "type": "Class"}]}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_baseline_or_regression", "type": "Function", "lineno": 144}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_accuracy_consistency", "type": "Function", "lineno": 230}]}, {"nodeid": "tests/test_regression.py::TestVersionComparison", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestVersionComparison::test_compare_model_versions", "type": "Function", "lineno": 254}]}, {"nodeid": "tests/test_regression.py::TestDegradationDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestDegradationDetection::test_no_memory_leak", "type": "Function", "lineno": 296}, {"nodeid": "tests/test_regression.py::TestDegradationDetection::test_fps_stability_over_time", "type": "Function", "lineno": 319}]}, {"nodeid": "tests/test_regression.py", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestRegressionMetrics", "type": "Class"}, {"nodeid": "tests/test_regression.py::TestVersionComparison", "type": "Class"}, {"nodeid": "tests/test_regression.py::TestDegradationDetection", "type": "Class"}]}, {"nodeid": "tests/test_simple.py::TestSetup", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestSetup::test_imports", "type": "Function", "lineno": 6}, {"nodeid": "tests/test_simple.py::TestSetup::test_project_structure", "type": "Function", "lineno": 13}]}, {"nodeid": "tests/test_simple.py::TestYOLOBasics", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_file_exists", "type": "Function", "lineno": 22}, {"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_loads", "type": "Function", "lineno": 31}]}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_at_least_one_image_exists", "type": "Function", "lineno": 39}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_can_load_image", "type": "Function", "lineno": 47}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_detection_runs", "type": "Function", "lineno": 57}]}, {"nodeid": "tests/test_simple.py", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestSetup", "type": "Class"}, {"nodeid": "tests/test_simple.py::TestYOLOBasics", "type": "Class"}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal", "type": "Class"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/models", "type": "Dir"}, {"nodeid": "tests/test_functional.py", "type": "Module"}, {"nodeid": "tests/test_performance.py", "type": "Module"}, {"nodeid": "tests/test_regression.py", "type": "Module"}, {"nodeid": "tests/test_simple.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_on_known_image", "lineno": 27, "outcome": "passed", "keywords": ["test_detection_on_known_image", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.05766019970178604, "outcome": "passed"}, "call": {"duration": 0.185532100033015, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 97.4ms\nSpeed: 3.0ms preprocess, 97.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.0011776001192629337, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_result_format", "lineno": 42, "outcome": "passed", "keywords": ["test_detection_result_format", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003945999778807163, "outcome": "passed"}, "call": {"duration": 0.11072999984025955, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 97.7ms\nSpeed: 2.8ms preprocess, 97.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.0004377998411655426, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_confidence_threshold_works", "lineno": 58, "outcome": "passed", "keywords": ["test_confidence_threshold_works", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0004150001332163811, "outcome": "passed"}, "call": {"duration": 0.21121190022677183, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 2 couchs, 2 remotes, 100.9ms\nSpeed: 2.3ms preprocess, 100.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 88.8ms\nSpeed: 2.2ms preprocess, 88.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.00037239957600831985, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_normal_dataset", "lineno": 84, "outcome": "passed", "keywords": ["test_detection_on_normal_dataset", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.05472550028935075, "outcome": "passed"}, "call": {"duration": 0.6318723997101188, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 87.8ms\nSpeed: 2.3ms preprocess, 87.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 105.2ms\nSpeed: 2.6ms preprocess, 105.2ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 152.0ms\nSpeed: 3.4ms preprocess, 152.0ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 115.5ms\nSpeed: 3.0ms preprocess, 115.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 76.5ms\nSpeed: 3.9ms preprocess, 76.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u2705 5 images trait\u00e9es\n   \u2705 5/5 avec d\u00e9tections (100.0%)\n"}, "teardown": {"duration": 0.0003575999289751053, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_edge_cases_dataset", "lineno": 107, "outcome": "passed", "keywords": ["test_detection_on_edge_cases_dataset", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0005683000199496746, "outcome": "passed"}, "call": {"duration": 1.7861869996413589, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 79.3ms\nSpeed: 2.1ms preprocess, 79.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 1 donut, 67.5ms\nSpeed: 2.5ms preprocess, 67.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 58.8ms\nSpeed: 1.8ms preprocess, 58.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 2 cups, 1 toilet, 60.3ms\nSpeed: 1.8ms preprocess, 60.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 57.8ms\nSpeed: 1.9ms preprocess, 57.8ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 62.8ms\nSpeed: 1.9ms preprocess, 62.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 59.0ms\nSpeed: 2.5ms preprocess, 59.0ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 61.9ms\nSpeed: 1.8ms preprocess, 61.9ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 68.6ms\nSpeed: 1.9ms preprocess, 68.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 1 sink, 58.7ms\nSpeed: 1.4ms preprocess, 58.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 dogs, 1 remote, 63.3ms\nSpeed: 1.9ms preprocess, 63.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 1 dining table, 1 refrigerator, 72.6ms\nSpeed: 2.4ms preprocess, 72.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 60.7ms\nSpeed: 1.9ms preprocess, 60.7ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 (no detections), 60.4ms\nSpeed: 1.8ms preprocess, 60.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 60.0ms\nSpeed: 1.5ms preprocess, 60.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 2 remotes, 62.8ms\nSpeed: 2.0ms preprocess, 62.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 (no detections), 60.0ms\nSpeed: 2.5ms preprocess, 60.0ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 65.6ms\nSpeed: 1.9ms preprocess, 65.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 (no detections), 67.3ms\nSpeed: 1.9ms preprocess, 67.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 63.3ms\nSpeed: 1.9ms preprocess, 63.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 1 remote, 64.4ms\nSpeed: 1.9ms preprocess, 64.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 63.9ms\nSpeed: 2.5ms preprocess, 63.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 66.6ms\nSpeed: 1.9ms preprocess, 66.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 4 toilets, 64.1ms\nSpeed: 1.8ms preprocess, 64.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 1 sink, 69.9ms\nSpeed: 2.1ms preprocess, 69.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u2705 25 edge cases trait\u00e9es\n   \u2705 79 d\u00e9tections au total\n   \u26a0\ufe0f  76.0% avec d\u00e9tections (d\u00e9gradation attendue)\n"}, "teardown": {"duration": 0.0003291997127234936, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_inference_time_reasonable", "lineno": 127, "outcome": "passed", "keywords": ["test_inference_time_reasonable", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003320998512208462, "outcome": "passed"}, "call": {"duration": 0.37969600036740303, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 83.4ms\nSpeed: 2.3ms preprocess, 83.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 61.3ms\nSpeed: 2.5ms preprocess, 61.3ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 66.1ms\nSpeed: 1.9ms preprocess, 66.1ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 62.2ms\nSpeed: 1.8ms preprocess, 62.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 57.9ms\nSpeed: 1.8ms preprocess, 57.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u23f1\ufe0f  Temps moyen : 71.85ms\n   \u23f1\ufe0f  Temps max : 89.75ms\n"}, "teardown": {"duration": 0.00038219988346099854, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_detect_by_category", "lineno": 153, "outcome": "passed", "keywords": ["test_detect_by_category", "TestDatasetByCategory", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0516780000180006, "outcome": "passed"}, "call": {"duration": 2.1160550001077354, "outcome": "passed", "stdout": "\n\ud83d\udcc2 Traitement par cat\u00e9gorie...\n   Base : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\n   Cat\u00e9gories trouv\u00e9es : 2\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : EDGE_CASES\n============================================================\n\n\ud83d\udcca Traitement de 25 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\edge_cases\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 65.5ms\nSpeed: 2.2ms preprocess, 65.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n[1/25] blur_cats_sofa.jpg             \u2192  2 objets ( 97.64ms)\n\n0: 448x640 1 donut, 59.3ms\nSpeed: 2.5ms preprocess, 59.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[2/25] blur_kitchen.jpg               \u2192  1 objets ( 64.21ms)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 60.3ms\nSpeed: 1.8ms preprocess, 60.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n[3/25] blur_person_kitchen.jpg        \u2192  5 objets ( 65.48ms)\n\n0: 640x448 2 cups, 1 toilet, 61.6ms\nSpeed: 1.8ms preprocess, 61.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[4/25] blur_toilet.jpg                \u2192  3 objets ( 66.39ms)\n\n0: 448x640 (no detections), 59.2ms\nSpeed: 1.8ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n[5/25] blur_washbasin.jpg             \u2192  0 objets ( 62.43ms)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.7ms\nSpeed: 2.0ms preprocess, 64.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n[6/25] dark_cats_sofa.jpg             \u2192  5 objets ( 70.41ms)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 60.0ms\nSpeed: 2.5ms preprocess, 60.0ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n[7/25] dark_kitchen.jpg               \u2192  8 objets ( 66.44ms)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 59.2ms\nSpeed: 1.9ms preprocess, 59.2ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n[8/25] dark_person_kitchen.jpg        \u2192 10 objets ( 65.74ms)\n\n0: 640x448 1 toilet, 71.5ms\nSpeed: 2.2ms preprocess, 71.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n[9/25] dark_toilet.jpg                \u2192  1 objets ( 76.08ms)\n\n0: 448x640 1 sink, 60.2ms\nSpeed: 1.9ms preprocess, 60.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[10/25] dark_washbasin.jpg             \u2192  1 objets ( 64.55ms)\n\n0: 480x640 2 dogs, 1 remote, 65.7ms\nSpeed: 2.0ms preprocess, 65.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n[11/25] lowres_cats_sofa.jpg           \u2192  3 objets ( 70.74ms)\n\n0: 448x640 1 dining table, 1 refrigerator, 62.4ms\nSpeed: 2.5ms preprocess, 62.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n[12/25] lowres_kitchen.jpg             \u2192  2 objets ( 67.59ms)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 59.4ms\nSpeed: 1.8ms preprocess, 59.4ms inference, 2.5ms postprocess per image at shape (1, 3, 448, 640)\n[13/25] lowres_person_kitchen.jpg      \u2192  8 objets ( 65.51ms)\n\n0: 640x448 (no detections), 60.3ms\nSpeed: 1.8ms preprocess, 60.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n[14/25] lowres_toilet.jpg              \u2192  0 objets ( 63.36ms)\n\n0: 448x640 (no detections), 71.4ms\nSpeed: 1.8ms preprocess, 71.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[15/25] lowres_washbasin.jpg           \u2192  0 objets ( 74.47ms)\n\n0: 480x640 2 cats, 2 remotes, 64.2ms\nSpeed: 2.0ms preprocess, 64.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[16/25] noisy_cats_sofa.jpg            \u2192  4 objets ( 69.43ms)\n\n0: 448x640 (no detections), 59.2ms\nSpeed: 2.5ms preprocess, 59.2ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[17/25] noisy_kitchen.jpg              \u2192  0 objets ( 62.89ms)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 61.1ms\nSpeed: 1.9ms preprocess, 61.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n[18/25] noisy_person_kitchen.jpg       \u2192  6 objets ( 66.35ms)\n\n0: 640x448 (no detections), 61.5ms\nSpeed: 1.9ms preprocess, 61.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n[19/25] noisy_toilet.jpg               \u2192  0 objets ( 64.69ms)\n\n0: 448x640 (no detections), 60.5ms\nSpeed: 1.9ms preprocess, 60.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[20/25] noisy_washbasin.jpg            \u2192  0 objets ( 63.64ms)\n\n0: 480x640 2 cats, 1 remote, 62.9ms\nSpeed: 2.0ms preprocess, 62.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n[21/25] rotated_cats_sofa.jpg          \u2192  3 objets ( 67.87ms)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 60.0ms\nSpeed: 2.5ms preprocess, 60.0ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[22/25] rotated_kitchen.jpg            \u2192  7 objets ( 66.45ms)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 68.4ms\nSpeed: 2.2ms preprocess, 68.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n[23/25] rotated_person_kitchen.jpg     \u2192  5 objets ( 74.12ms)\n\n0: 640x448 4 toilets, 59.1ms\nSpeed: 1.8ms preprocess, 59.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[24/25] rotated_toilet.jpg             \u2192  4 objets ( 63.78ms)\n\n0: 448x640 1 sink, 59.7ms\nSpeed: 1.8ms preprocess, 59.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[25/25] rotated_washbasin.jpg          \u2192  1 objets ( 64.01ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 25\nD\u00e9tections totales    : 79\nD\u00e9tections par image  : 3.16\nTemps moyen           : 68.17ms\nTemps min/max         : 62.43ms / 97.64ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : NORMAL\n============================================================\n\n\ud83d\udcca Traitement de 5 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\normal\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.9ms\nSpeed: 1.9ms preprocess, 63.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n[1/5] cats_sofa.jpg                  \u2192  5 objets ( 69.42ms)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 56.3ms\nSpeed: 2.5ms preprocess, 56.3ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n[2/5] kitchen.jpg                    \u2192 10 objets ( 63.51ms)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 58.8ms\nSpeed: 1.9ms preprocess, 58.8ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n[3/5] person_kitchen.jpg             \u2192  9 objets ( 64.91ms)\n\n0: 640x448 1 toilet, 59.1ms\nSpeed: 1.8ms preprocess, 59.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n[4/5] toilet.jpg                     \u2192  1 objets ( 62.79ms)\n\n0: 448x640 2 sinks, 58.8ms\nSpeed: 1.4ms preprocess, 58.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n[5/5] washbasin.jpg                  \u2192  2 objets ( 62.88ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 5\nD\u00e9tections totales    : 27\nD\u00e9tections par image  : 5.40\nTemps moyen           : 64.70ms\nTemps min/max         : 62.79ms / 69.42ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcca R\u00c9SUM\u00c9 GLOBAL\n============================================================\nedge_cases           :  25 images,   79 d\u00e9tections, moy=68.17ms\nnormal               :   5 images,   27 d\u00e9tections, moy=64.70ms\n\n   \ud83d\udcc2 Cat\u00e9gories trouv\u00e9es : ['edge_cases', 'normal']\n   \u2705 edge_cases      : 25 images, 79 d\u00e9tections\n   \u2705 normal          : 5 images, 27 d\u00e9tections\n"}, "teardown": {"duration": 0.00033789966255426407, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_compare_normal_vs_edge_cases", "lineno": 172, "outcome": "passed", "keywords": ["test_compare_normal_vs_edge_cases", "TestDatasetByCategory", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003065001219511032, "outcome": "passed"}, "call": {"duration": 2.236028399784118, "outcome": "passed", "stdout": "\n\ud83d\udcc2 Traitement par cat\u00e9gorie...\n   Base : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\n   Cat\u00e9gories trouv\u00e9es : 2\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : EDGE_CASES\n============================================================\n\n\ud83d\udcca Traitement de 25 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\edge_cases\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 73.3ms\nSpeed: 1.9ms preprocess, 73.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n[1/25] blur_cats_sofa.jpg             \u2192  2 objets ( 77.60ms)\n\n0: 448x640 1 donut, 59.5ms\nSpeed: 2.5ms preprocess, 59.5ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n[2/25] blur_kitchen.jpg               \u2192  1 objets ( 63.84ms)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 58.6ms\nSpeed: 1.8ms preprocess, 58.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[3/25] blur_person_kitchen.jpg        \u2192  5 objets ( 63.83ms)\n\n0: 640x448 2 cups, 1 toilet, 66.0ms\nSpeed: 1.8ms preprocess, 66.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[4/25] blur_toilet.jpg                \u2192  3 objets ( 70.81ms)\n\n0: 448x640 (no detections), 62.4ms\nSpeed: 1.9ms preprocess, 62.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[5/25] blur_washbasin.jpg             \u2192  0 objets ( 65.49ms)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.5ms\nSpeed: 2.1ms preprocess, 65.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n[6/25] dark_cats_sofa.jpg             \u2192  5 objets ( 71.09ms)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 66.5ms\nSpeed: 2.5ms preprocess, 66.5ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n[7/25] dark_kitchen.jpg               \u2192  8 objets ( 73.00ms)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 63.0ms\nSpeed: 1.9ms preprocess, 63.0ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n[8/25] dark_person_kitchen.jpg        \u2192 10 objets ( 69.68ms)\n\n0: 640x448 1 toilet, 62.1ms\nSpeed: 1.9ms preprocess, 62.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n[9/25] dark_toilet.jpg                \u2192  1 objets ( 66.56ms)\n\n0: 448x640 1 sink, 65.4ms\nSpeed: 2.0ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n[10/25] dark_washbasin.jpg             \u2192  1 objets ( 70.11ms)\n\n0: 480x640 2 dogs, 1 remote, 73.1ms\nSpeed: 2.1ms preprocess, 73.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n[11/25] lowres_cats_sofa.jpg           \u2192  3 objets ( 78.35ms)\n\n0: 448x640 1 dining table, 1 refrigerator, 70.9ms\nSpeed: 2.5ms preprocess, 70.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n[12/25] lowres_kitchen.jpg             \u2192  2 objets ( 76.50ms)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 80.8ms\nSpeed: 2.0ms preprocess, 80.8ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n[13/25] lowres_person_kitchen.jpg      \u2192  8 objets ( 87.51ms)\n\n0: 640x448 (no detections), 64.4ms\nSpeed: 1.9ms preprocess, 64.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n[14/25] lowres_toilet.jpg              \u2192  0 objets ( 67.69ms)\n\n0: 448x640 (no detections), 71.5ms\nSpeed: 2.0ms preprocess, 71.5ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n[15/25] lowres_washbasin.jpg           \u2192  0 objets ( 74.90ms)\n\n0: 480x640 2 cats, 2 remotes, 80.9ms\nSpeed: 2.2ms preprocess, 80.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[16/25] noisy_cats_sofa.jpg            \u2192  4 objets ( 86.32ms)\n\n0: 448x640 (no detections), 64.4ms\nSpeed: 2.6ms preprocess, 64.4ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n[17/25] noisy_kitchen.jpg              \u2192  0 objets ( 68.28ms)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 60.3ms\nSpeed: 1.9ms preprocess, 60.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[18/25] noisy_person_kitchen.jpg       \u2192  6 objets ( 65.84ms)\n\n0: 640x448 (no detections), 63.5ms\nSpeed: 2.3ms preprocess, 63.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n[19/25] noisy_toilet.jpg               \u2192  0 objets ( 67.14ms)\n\n0: 448x640 (no detections), 73.8ms\nSpeed: 1.9ms preprocess, 73.8ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n[20/25] noisy_washbasin.jpg            \u2192  0 objets ( 77.02ms)\n\n0: 480x640 2 cats, 1 remote, 65.8ms\nSpeed: 1.9ms preprocess, 65.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n[21/25] rotated_cats_sofa.jpg          \u2192  3 objets ( 71.05ms)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 62.3ms\nSpeed: 2.6ms preprocess, 62.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n[22/25] rotated_kitchen.jpg            \u2192  7 objets ( 68.66ms)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 64.1ms\nSpeed: 1.9ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n[23/25] rotated_person_kitchen.jpg     \u2192  5 objets ( 69.49ms)\n\n0: 640x448 4 toilets, 62.4ms\nSpeed: 1.9ms preprocess, 62.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[24/25] rotated_toilet.jpg             \u2192  4 objets ( 67.22ms)\n\n0: 448x640 1 sink, 61.1ms\nSpeed: 1.9ms preprocess, 61.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[25/25] rotated_washbasin.jpg          \u2192  1 objets ( 65.46ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 25\nD\u00e9tections totales    : 79\nD\u00e9tections par image  : 3.16\nTemps moyen           : 71.34ms\nTemps min/max         : 63.83ms / 87.51ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : NORMAL\n============================================================\n\n\ud83d\udcca Traitement de 5 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\normal\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.3ms\nSpeed: 2.0ms preprocess, 65.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n[1/5] cats_sofa.jpg                  \u2192  5 objets ( 70.80ms)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 61.7ms\nSpeed: 2.5ms preprocess, 61.7ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n[2/5] kitchen.jpg                    \u2192 10 objets ( 69.04ms)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 78.6ms\nSpeed: 2.1ms preprocess, 78.6ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n[3/5] person_kitchen.jpg             \u2192  9 objets ( 85.42ms)\n\n0: 640x448 1 toilet, 65.0ms\nSpeed: 2.1ms preprocess, 65.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n[4/5] toilet.jpg                     \u2192  1 objets ( 69.67ms)\n\n0: 448x640 2 sinks, 62.0ms\nSpeed: 1.9ms preprocess, 62.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n[5/5] washbasin.jpg                  \u2192  2 objets ( 66.98ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 5\nD\u00e9tections totales    : 27\nD\u00e9tections par image  : 5.40\nTemps moyen           : 72.38ms\nTemps min/max         : 66.98ms / 85.42ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcca R\u00c9SUM\u00c9 GLOBAL\n============================================================\nedge_cases           :  25 images,   79 d\u00e9tections, moy=71.34ms\nnormal               :   5 images,   27 d\u00e9tections, moy=72.38ms\n\n   \ud83d\udcca D\u00e9tections par image :\n      Normal     : 5.40\n      Edge cases : 3.16\n      D\u00e9gradation: 41.5%\n"}, "teardown": {"duration": 0.0003733998164534569, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_creates_file", "lineno": 207, "outcome": "passed", "keywords": ["test_save_results_creates_file", "TestResultsSaving", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.06410120008513331, "outcome": "passed"}, "call": {"duration": 0.4079475002363324, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 68.5ms\nSpeed: 2.1ms preprocess, 68.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 67.4ms\nSpeed: 2.5ms preprocess, 67.4ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 61.7ms\nSpeed: 2.0ms preprocess, 61.7ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 64.8ms\nSpeed: 1.9ms preprocess, 64.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 65.8ms\nSpeed: 1.9ms preprocess, 65.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n\n\u2705 R\u00e9sultats sauvegard\u00e9s : C:\\Users\\hp\\AppData\\Local\\Temp\\pytest-of-hp\\pytest-13\\test_save_results_creates_file0\\test_results.json\n   - 5 images trait\u00e9es\n   - 27 d\u00e9tections au total\n"}, "teardown": {"duration": 0.0004608999006450176, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_json_format", "lineno": 220, "outcome": "passed", "keywords": ["test_save_results_json_format", "TestResultsSaving", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.002642699982970953, "outcome": "passed"}, "call": {"duration": 0.5115698999725282, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 154.4ms\nSpeed: 2.3ms preprocess, 154.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 82.8ms\nSpeed: 2.6ms preprocess, 82.8ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 63.1ms\nSpeed: 1.9ms preprocess, 63.1ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 66.3ms\nSpeed: 2.0ms preprocess, 66.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 73.7ms\nSpeed: 2.1ms preprocess, 73.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n\u2705 R\u00e9sultats sauvegard\u00e9s : C:\\Users\\hp\\AppData\\Local\\Temp\\pytest-of-hp\\pytest-13\\test_save_results_json_format0\\test_results.json\n   - 5 images trait\u00e9es\n   - 27 d\u00e9tections au total\n\n   \u2705 JSON valide avec 5 images\n"}, "teardown": {"duration": 0.0004400997422635555, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_cold_start_latency", "lineno": 27, "outcome": "passed", "keywords": ["test_cold_start_latency", "TestLatencyPerformance", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.06783910002559423, "outcome": "passed"}, "call": {"duration": 0.174509699922055, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 77.8ms\nSpeed: 2.3ms preprocess, 77.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83e\udd76 Cold start: 119.80ms\n"}, "teardown": {"duration": 0.0003659999929368496, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_warm_inference_latency", "lineno": 41, "outcome": "passed", "keywords": ["test_warm_inference_latency", "TestLatencyPerformance", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003483002074062824, "outcome": "passed"}, "call": {"duration": 1.9611786999739707, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 73.9ms\nSpeed: 2.5ms preprocess, 73.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 66.6ms\nSpeed: 1.9ms preprocess, 66.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 92.0ms\nSpeed: 2.1ms preprocess, 92.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.8ms\nSpeed: 2.3ms preprocess, 81.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 69.0ms\nSpeed: 2.0ms preprocess, 69.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.4ms\nSpeed: 1.8ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.7ms\nSpeed: 1.9ms preprocess, 63.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.2ms\nSpeed: 1.5ms preprocess, 63.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.2ms\nSpeed: 1.9ms preprocess, 65.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.4ms\nSpeed: 2.2ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.4ms\nSpeed: 2.0ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 71.4ms\nSpeed: 1.9ms preprocess, 71.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.8ms\nSpeed: 1.9ms preprocess, 64.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.3ms\nSpeed: 1.9ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.0ms\nSpeed: 1.9ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.3ms\nSpeed: 1.9ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.8ms\nSpeed: 1.9ms preprocess, 63.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 61.5ms\nSpeed: 1.9ms preprocess, 61.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.9ms\nSpeed: 1.9ms preprocess, 63.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.5ms\nSpeed: 1.9ms preprocess, 63.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.1ms\nSpeed: 2.0ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.4ms\nSpeed: 1.5ms preprocess, 63.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 66.9ms\nSpeed: 2.3ms preprocess, 66.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.9ms\nSpeed: 1.9ms preprocess, 63.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 66.1ms\nSpeed: 1.9ms preprocess, 66.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83d\udcca Latence (20 runs):\n      Moyenne : 74.57ms\n      P50     : 74.27ms\n      P95     : 81.52ms\n"}, "teardown": {"duration": 0.00033529987558722496, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_latency_variance", "lineno": 67, "outcome": "passed", "keywords": ["test_latency_variance", "TestLatencyPerformance", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.00031560007482767105, "outcome": "passed"}, "call": {"duration": 2.548355100210756, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.1ms\nSpeed: 2.4ms preprocess, 84.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.4ms\nSpeed: 2.0ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.1ms\nSpeed: 1.5ms preprocess, 64.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.0ms\nSpeed: 1.9ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.0ms\nSpeed: 1.9ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 61.2ms\nSpeed: 2.0ms preprocess, 61.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 62.1ms\nSpeed: 1.9ms preprocess, 62.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.1ms\nSpeed: 1.5ms preprocess, 64.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.4ms\nSpeed: 2.1ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 62.6ms\nSpeed: 1.5ms preprocess, 62.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 70.9ms\nSpeed: 1.5ms preprocess, 70.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 66.4ms\nSpeed: 1.4ms preprocess, 66.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 68.1ms\nSpeed: 2.0ms preprocess, 68.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 68.6ms\nSpeed: 2.0ms preprocess, 68.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 72.9ms\nSpeed: 2.1ms preprocess, 72.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 72.5ms\nSpeed: 2.1ms preprocess, 72.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 74.9ms\nSpeed: 2.6ms preprocess, 74.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 72.8ms\nSpeed: 2.5ms preprocess, 72.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 77.9ms\nSpeed: 2.8ms preprocess, 77.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 73.6ms\nSpeed: 2.7ms preprocess, 73.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.8ms\nSpeed: 2.2ms preprocess, 81.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 77.6ms\nSpeed: 2.3ms preprocess, 77.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 82.7ms\nSpeed: 2.8ms preprocess, 82.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 79.7ms\nSpeed: 2.8ms preprocess, 79.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 91.0ms\nSpeed: 2.2ms preprocess, 91.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.0ms\nSpeed: 2.5ms preprocess, 81.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 83.6ms\nSpeed: 2.4ms preprocess, 83.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 82.8ms\nSpeed: 2.9ms preprocess, 82.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 85.9ms\nSpeed: 3.0ms preprocess, 85.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 86.9ms\nSpeed: 2.4ms preprocess, 86.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83d\udcc8 Variance:\n      Moyenne : 84.91ms\n      Std Dev : 10.62ms\n      CV      : 12.5%\n"}, "teardown": {"duration": 0.0004933997988700867, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_cpu_usage_during_inference", "lineno": 95, "outcome": "skipped", "keywords": ["test_cpu_usage_during_inference", "TestResourceUsage", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.07225390011444688, "outcome": "passed"}, "call": {"duration": 2.968237000051886, "outcome": "skipped", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 72.3ms\nSpeed: 2.3ms preprocess, 72.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 75.6ms\nSpeed: 2.2ms preprocess, 75.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 69.8ms\nSpeed: 2.1ms preprocess, 69.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.0ms\nSpeed: 2.8ms preprocess, 81.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 95.9ms\nSpeed: 2.4ms preprocess, 95.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 88.8ms\nSpeed: 2.3ms preprocess, 88.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 76.8ms\nSpeed: 2.5ms preprocess, 76.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 91.1ms\nSpeed: 2.5ms preprocess, 91.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 77.0ms\nSpeed: 2.6ms preprocess, 77.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 75.4ms\nSpeed: 2.9ms preprocess, 75.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83d\udcbb CPU Usage:\n      Moyenne : 89.5%\n      Maximum : 100.0%\n      Env     : Local\n", "longrepr": "('C:\\\\Users\\\\hp\\\\OneDrive\\\\Documents\\\\my_projects\\\\Yolo\\\\tests\\\\test_performance.py', 122, 'Skipped: CPU satur\u00e9 en local - normal avec autres processus')"}, "teardown": {"duration": 0.00042419973760843277, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_memory_usage", "lineno": 129, "outcome": "passed", "keywords": ["test_memory_usage", "TestResourceUsage", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.00040190014988183975, "outcome": "passed"}, "call": {"duration": 0.49499320005998015, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 92.6ms\nSpeed: 3.2ms preprocess, 92.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 92.3ms\nSpeed: 3.1ms preprocess, 92.3ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 75.5ms\nSpeed: 2.3ms preprocess, 75.5ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 90.1ms\nSpeed: 3.2ms preprocess, 90.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 79.9ms\nSpeed: 2.2ms preprocess, 79.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n\n   \ud83e\udde0 Memory Usage:\n      Avant   : 343.9 MB\n      Apr\u00e8s   : 343.9 MB\n      Augment.: 0.0 MB\n"}, "teardown": {"duration": 0.00043850019574165344, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_gpu_availability_check", "lineno": 149, "outcome": "passed", "keywords": ["test_gpu_availability_check", "TestResourceUsage", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003651999868452549, "outcome": "passed"}, "call": {"duration": 0.0006165998056530952, "outcome": "passed", "stdout": "\n   \u2139\ufe0f  Aucun GPU d\u00e9tect\u00e9 - utilisation CPU\n"}, "teardown": {"duration": 0.0004561999812722206, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestFPSRealTime::test_sustained_fps", "lineno": 173, "outcome": "passed", "keywords": ["test_sustained_fps", "TestFPSRealTime", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.07504070037975907, "outcome": "passed"}, "call": {"duration": 5.4836506000719965, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 85.3ms\nSpeed: 2.3ms preprocess, 85.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.0ms\nSpeed: 2.8ms preprocess, 81.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 87.3ms\nSpeed: 2.6ms preprocess, 87.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 86.7ms\nSpeed: 2.6ms preprocess, 86.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 101.3ms\nSpeed: 2.4ms preprocess, 101.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 90.3ms\nSpeed: 2.8ms preprocess, 90.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 83.5ms\nSpeed: 2.4ms preprocess, 83.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 116.2ms\nSpeed: 2.7ms preprocess, 116.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 80.1ms\nSpeed: 2.6ms preprocess, 80.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 97.8ms\nSpeed: 2.4ms preprocess, 97.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 82.7ms\nSpeed: 3.1ms preprocess, 82.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.0ms\nSpeed: 2.5ms preprocess, 81.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 79.6ms\nSpeed: 3.0ms preprocess, 79.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 83.0ms\nSpeed: 3.0ms preprocess, 83.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 81.1ms\nSpeed: 2.6ms preprocess, 81.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 89.4ms\nSpeed: 3.3ms preprocess, 89.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 80.1ms\nSpeed: 2.8ms preprocess, 80.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 80.3ms\nSpeed: 2.5ms preprocess, 80.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.8ms\nSpeed: 3.3ms preprocess, 127.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 129.8ms\nSpeed: 2.7ms preprocess, 129.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.7ms\nSpeed: 3.0ms preprocess, 127.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.7ms\nSpeed: 2.7ms preprocess, 124.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 115.3ms\nSpeed: 2.9ms preprocess, 115.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 108.4ms\nSpeed: 3.2ms preprocess, 108.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 91.7ms\nSpeed: 2.5ms preprocess, 91.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 94.8ms\nSpeed: 2.6ms preprocess, 94.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 104.9ms\nSpeed: 2.8ms preprocess, 104.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 88.3ms\nSpeed: 2.7ms preprocess, 88.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 86.8ms\nSpeed: 2.5ms preprocess, 86.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 107.3ms\nSpeed: 2.7ms preprocess, 107.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.0ms\nSpeed: 2.9ms preprocess, 84.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 90.8ms\nSpeed: 2.4ms preprocess, 90.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.9ms\nSpeed: 2.5ms preprocess, 84.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 80.0ms\nSpeed: 2.4ms preprocess, 80.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 82.7ms\nSpeed: 2.7ms preprocess, 82.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 94.9ms\nSpeed: 2.9ms preprocess, 94.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 113.4ms\nSpeed: 3.1ms preprocess, 113.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 108.1ms\nSpeed: 2.6ms preprocess, 108.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 119.2ms\nSpeed: 2.9ms preprocess, 119.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 106.0ms\nSpeed: 3.0ms preprocess, 106.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 88.6ms\nSpeed: 2.4ms preprocess, 88.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 98.0ms\nSpeed: 2.5ms preprocess, 98.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 89.0ms\nSpeed: 2.6ms preprocess, 89.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 107.9ms\nSpeed: 2.8ms preprocess, 107.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 83.1ms\nSpeed: 2.6ms preprocess, 83.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 85.3ms\nSpeed: 3.1ms preprocess, 85.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 99.1ms\nSpeed: 2.6ms preprocess, 99.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 78.7ms\nSpeed: 2.6ms preprocess, 78.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 90.3ms\nSpeed: 2.9ms preprocess, 90.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 85.2ms\nSpeed: 2.9ms preprocess, 85.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83c\udfac FPS Performance:\n      Frames  : 50\n      Dur\u00e9e   : 5.48s\n      FPS     : 9.1\n"}, "teardown": {"duration": 0.0004585999995470047, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestFPSRealTime::test_batch_vs_single_inference", "lineno": 192, "outcome": "passed", "keywords": ["test_batch_vs_single_inference", "TestFPSRealTime", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.00043269991874694824, "outcome": "passed"}, "call": {"duration": 1.2434148001484573, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 96.7ms\nSpeed: 2.7ms preprocess, 96.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 111.5ms\nSpeed: 3.5ms preprocess, 111.5ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 104.0ms\nSpeed: 2.5ms preprocess, 104.0ms inference, 3.8ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 115.9ms\nSpeed: 2.5ms preprocess, 115.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 102.3ms\nSpeed: 2.5ms preprocess, 102.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 108.0ms\nSpeed: 3.2ms preprocess, 108.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 143.5ms\nSpeed: 3.6ms preprocess, 143.5ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 141.3ms\nSpeed: 2.7ms preprocess, 141.3ms inference, 3.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 88.2ms\nSpeed: 3.1ms preprocess, 88.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 95.3ms\nSpeed: 2.3ms preprocess, 95.3ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u26a1 Batch vs Single:\n      Single : 8.4 FPS\n      Batch  : 7.7 FPS\n      Speedup: 0.92x\n"}, "teardown": {"duration": 0.0005184998735785484, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestModelBenchmarking::test_yolov8_model_variants", "lineno": 222, "outcome": "passed", "keywords": ["test_yolov8_model_variants", "TestModelBenchmarking", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.00044950004667043686, "outcome": "passed"}, "call": {"duration": 0.950902699958533, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 119.0ms\nSpeed: 3.4ms preprocess, 119.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 135.4ms\nSpeed: 4.0ms preprocess, 135.4ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 134.3ms\nSpeed: 4.4ms preprocess, 134.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 119.1ms\nSpeed: 4.0ms preprocess, 119.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 100.3ms\nSpeed: 2.5ms preprocess, 100.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 132.9ms\nSpeed: 3.3ms preprocess, 132.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83c\udfc6 Benchmark Mod\u00e8le:\n      yolov8n.pt     :  139.9ms (D\u00e9tections: 5)\n"}, "teardown": {"duration": 0.0004616999067366123, "outcome": "passed"}}, {"nodeid": "tests/test_performance.py::TestSystemInfo::test_collect_system_info", "lineno": 259, "outcome": "passed", "keywords": ["test_collect_system_info", "TestSystemInfo", "performance", "test_performance.py", "tests", "Yolo", ""], "setup": {"duration": 0.0028777001425623894, "outcome": "passed"}, "call": {"duration": 0.007695500273257494, "outcome": "passed", "stdout": "\n   \ud83d\udcbe System Info:\n      platform            : Windows-10-10.0.19045-SP0\n      processor           : Intel64 Family 6 Model 142 Stepping 12, GenuineIntel\n      cpu_count           : 8\n      cpu_freq            : 1600.0\n      ram_total_gb        : 15.810821533203125\n      python_version      : 3.13.7\n      pytorch_version     : 2.9.1+cpu\n      cuda_available      : False\n      is_ci               : False\n"}, "teardown": {"duration": 0.000497900415211916, "outcome": "passed"}}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_baseline_or_regression", "lineno": 144, "outcome": "passed", "keywords": ["test_baseline_or_regression", "TestRegressionMetrics", "regression", "test_regression.py", "tests", "Yolo", ""], "setup": {"duration": 0.07911229971796274, "outcome": "passed"}, "call": {"duration": 1.804284599609673, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 112.0ms\nSpeed: 3.4ms preprocess, 112.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 89.7ms\nSpeed: 2.7ms preprocess, 89.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 92.2ms\nSpeed: 2.7ms preprocess, 92.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 101.9ms\nSpeed: 2.9ms preprocess, 101.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 102.6ms\nSpeed: 3.0ms preprocess, 102.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 96.6ms\nSpeed: 2.7ms preprocess, 96.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 101.4ms\nSpeed: 2.4ms preprocess, 101.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 99.3ms\nSpeed: 2.8ms preprocess, 99.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.3ms\nSpeed: 3.0ms preprocess, 124.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 130.6ms\nSpeed: 3.4ms preprocess, 130.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.5ms\nSpeed: 2.9ms preprocess, 127.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 101.0ms\nSpeed: 3.7ms preprocess, 101.0ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 92.8ms\nSpeed: 2.6ms preprocess, 92.8ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 88.8ms\nSpeed: 2.2ms preprocess, 88.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 88.8ms\nSpeed: 2.4ms preprocess, 88.8ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n\n   \ud83d\udcca M\u00e9triques Actuelles:\n      avg_latency_ms                : 123.49\n      p95_latency_ms                : 116.08\n      avg_detections_per_image      : 5.40\n      total_detections              : 27.00\n      num_images                    : 5.00\n\n   \ud83d\udcc8 Baseline Version: v1.0.0-auto\n   \ud83d\udcc5 Baseline Date: 2026-01-05 12:05:38\n\n   \ud83d\udd0d Comparaison vs Baseline (Tol\u00e9rance: \u00b120%):\n      avg_latency_ms                :   123.49 (baseline: 309.65, -60.1%) \u26a0\ufe0f  WARNING\n      p95_latency_ms                :   116.08 (baseline: 251.57, -53.9%) \u26a0\ufe0f  WARNING\n      avg_detections_per_image      :     5.40 (baseline: 5.40, ++0.0%) \u2705 OK\n      total_detections              :    27.00 (baseline: 27.00, ++0.0%) \u2705 OK\n      num_images                    :     5.00 (baseline: 5.00, ++0.0%) \u2705 OK\n\n   \u26a0\ufe0f  2 warning(s) d\u00e9tect\u00e9(s) (10-20% de variation)\n\n   \u2705 Tous les tests de r\u00e9gression ont pass\u00e9 !\n"}, "teardown": {"duration": 0.0005465000867843628, "outcome": "passed"}}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_accuracy_consistency", "lineno": 230, "outcome": "passed", "keywords": ["test_accuracy_consistency", "TestRegressionMetrics", "regression", "test_regression.py", "tests", "Yolo", ""], "setup": {"duration": 0.0005179997533559799, "outcome": "passed"}, "call": {"duration": 0.6543264999054372, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 144.9ms\nSpeed: 2.7ms preprocess, 144.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 132.0ms\nSpeed: 2.5ms preprocess, 132.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 98.5ms\nSpeed: 3.0ms preprocess, 98.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 98.7ms\nSpeed: 2.5ms preprocess, 98.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 107.2ms\nSpeed: 2.7ms preprocess, 107.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83c\udfaf Coh\u00e9rence D\u00e9tections:\n      Runs        : 5\n      R\u00e9sultats   : [5, 5, 5, 5, 5]\n      Unique      : {5}\n"}, "teardown": {"duration": 0.0004905997775495052, "outcome": "passed"}}, {"nodeid": "tests/test_regression.py::TestVersionComparison::test_compare_model_versions", "lineno": 254, "outcome": "passed", "keywords": ["test_compare_model_versions", "TestVersionComparison", "regression", "test_regression.py", "tests", "Yolo", ""], "setup": {"duration": 0.00047060009092092514, "outcome": "passed"}, "call": {"duration": 0.7773871002718806, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 107.2ms\nSpeed: 3.8ms preprocess, 107.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 114.9ms\nSpeed: 3.0ms preprocess, 114.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 113.7ms\nSpeed: 4.0ms preprocess, 113.7ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 128.4ms\nSpeed: 2.6ms preprocess, 128.4ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.8ms\nSpeed: 3.0ms preprocess, 124.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83d\udd2c Comparaison Versions:\n      yolov8n   :  140.6ms, 5.0 d\u00e9tections\n"}, "teardown": {"duration": 0.0004754001274704933, "outcome": "passed"}}, {"nodeid": "tests/test_regression.py::TestDegradationDetection::test_no_memory_leak", "lineno": 296, "outcome": "passed", "keywords": ["test_no_memory_leak", "TestDegradationDetection", "regression", "test_regression.py", "tests", "Yolo", ""], "setup": {"duration": 0.08316619973629713, "outcome": "passed"}, "call": {"duration": 8.224831499624997, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 129.5ms\nSpeed: 3.8ms preprocess, 129.5ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 104.7ms\nSpeed: 3.0ms preprocess, 104.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 111.6ms\nSpeed: 2.5ms preprocess, 111.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 120.1ms\nSpeed: 2.5ms preprocess, 120.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 131.4ms\nSpeed: 3.1ms preprocess, 131.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 158.9ms\nSpeed: 2.8ms preprocess, 158.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 144.0ms\nSpeed: 2.7ms preprocess, 144.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.9ms\nSpeed: 3.6ms preprocess, 124.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 136.1ms\nSpeed: 2.6ms preprocess, 136.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 129.7ms\nSpeed: 3.3ms preprocess, 129.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 114.2ms\nSpeed: 2.6ms preprocess, 114.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 87.5ms\nSpeed: 3.0ms preprocess, 87.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 125.2ms\nSpeed: 2.6ms preprocess, 125.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 119.3ms\nSpeed: 2.6ms preprocess, 119.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 113.9ms\nSpeed: 2.7ms preprocess, 113.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 90.1ms\nSpeed: 2.8ms preprocess, 90.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 97.7ms\nSpeed: 2.6ms preprocess, 97.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 112.2ms\nSpeed: 2.8ms preprocess, 112.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 113.2ms\nSpeed: 2.6ms preprocess, 113.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 107.9ms\nSpeed: 2.5ms preprocess, 107.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.3ms\nSpeed: 2.7ms preprocess, 84.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 102.4ms\nSpeed: 2.4ms preprocess, 102.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.1ms\nSpeed: 3.0ms preprocess, 127.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 115.7ms\nSpeed: 3.1ms preprocess, 115.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 91.0ms\nSpeed: 2.4ms preprocess, 91.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 91.7ms\nSpeed: 2.9ms preprocess, 91.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.3ms\nSpeed: 2.7ms preprocess, 84.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 104.4ms\nSpeed: 2.7ms preprocess, 104.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 110.0ms\nSpeed: 2.7ms preprocess, 110.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 103.8ms\nSpeed: 3.0ms preprocess, 103.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 198.6ms\nSpeed: 3.4ms preprocess, 198.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 125.5ms\nSpeed: 3.0ms preprocess, 125.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 87.6ms\nSpeed: 2.4ms preprocess, 87.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 183.1ms\nSpeed: 2.5ms preprocess, 183.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 224.1ms\nSpeed: 2.8ms preprocess, 224.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 155.1ms\nSpeed: 3.3ms preprocess, 155.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 181.9ms\nSpeed: 5.0ms preprocess, 181.9ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 139.3ms\nSpeed: 7.1ms preprocess, 139.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 193.5ms\nSpeed: 3.8ms preprocess, 193.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 336.5ms\nSpeed: 4.2ms preprocess, 336.5ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 374.6ms\nSpeed: 19.5ms preprocess, 374.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 318.3ms\nSpeed: 10.9ms preprocess, 318.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 139.4ms\nSpeed: 3.0ms preprocess, 139.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 139.4ms\nSpeed: 3.5ms preprocess, 139.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 178.3ms\nSpeed: 2.6ms preprocess, 178.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 387.2ms\nSpeed: 7.1ms preprocess, 387.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 160.4ms\nSpeed: 2.8ms preprocess, 160.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 155.1ms\nSpeed: 4.1ms preprocess, 155.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 162.6ms\nSpeed: 3.1ms preprocess, 162.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 158.1ms\nSpeed: 2.7ms preprocess, 158.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n   \ud83e\udde0 Memory Leak Test:\n      Initial : 352.3 MB\n      Final   : 350.0 MB\n      Increase: -2.3 MB\n"}, "teardown": {"duration": 0.0004406999796628952, "outcome": "passed"}}, {"nodeid": "tests/test_regression.py::TestDegradationDetection::test_fps_stability_over_time", "lineno": 319, "outcome": "passed", "keywords": ["test_fps_stability_over_time", "TestDegradationDetection", "regression", "test_regression.py", "tests", "Yolo", ""], "setup": {"duration": 0.00047549977898597717, "outcome": "passed"}, "call": {"duration": 10.22705820016563, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 142.9ms\nSpeed: 2.7ms preprocess, 142.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 119.4ms\nSpeed: 2.8ms preprocess, 119.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 149.6ms\nSpeed: 3.4ms preprocess, 149.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 130.1ms\nSpeed: 2.8ms preprocess, 130.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 148.1ms\nSpeed: 2.8ms preprocess, 148.1ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 147.6ms\nSpeed: 4.6ms preprocess, 147.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 213.9ms\nSpeed: 3.3ms preprocess, 213.9ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 165.6ms\nSpeed: 3.2ms preprocess, 165.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 126.7ms\nSpeed: 2.8ms preprocess, 126.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 128.4ms\nSpeed: 3.1ms preprocess, 128.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.0ms\nSpeed: 2.8ms preprocess, 124.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 118.4ms\nSpeed: 2.7ms preprocess, 118.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 132.4ms\nSpeed: 2.7ms preprocess, 132.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 130.2ms\nSpeed: 3.2ms preprocess, 130.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 160.0ms\nSpeed: 3.0ms preprocess, 160.0ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 146.7ms\nSpeed: 3.8ms preprocess, 146.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 141.7ms\nSpeed: 3.8ms preprocess, 141.7ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 172.4ms\nSpeed: 2.9ms preprocess, 172.4ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 168.1ms\nSpeed: 5.6ms preprocess, 168.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 382.9ms\nSpeed: 2.9ms preprocess, 382.9ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 144.3ms\nSpeed: 2.9ms preprocess, 144.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 155.9ms\nSpeed: 2.9ms preprocess, 155.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 139.8ms\nSpeed: 2.8ms preprocess, 139.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 129.3ms\nSpeed: 2.8ms preprocess, 129.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 129.3ms\nSpeed: 2.8ms preprocess, 129.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 164.6ms\nSpeed: 4.7ms preprocess, 164.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 160.6ms\nSpeed: 3.4ms preprocess, 160.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 174.0ms\nSpeed: 5.0ms preprocess, 174.0ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 213.8ms\nSpeed: 4.2ms preprocess, 213.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 221.4ms\nSpeed: 2.9ms preprocess, 221.4ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 220.9ms\nSpeed: 5.0ms preprocess, 220.9ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 144.2ms\nSpeed: 3.4ms preprocess, 144.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 146.9ms\nSpeed: 3.1ms preprocess, 146.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 147.3ms\nSpeed: 3.2ms preprocess, 147.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.3ms\nSpeed: 2.6ms preprocess, 127.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 134.8ms\nSpeed: 2.6ms preprocess, 134.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 133.7ms\nSpeed: 3.1ms preprocess, 133.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 158.3ms\nSpeed: 2.7ms preprocess, 158.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 127.0ms\nSpeed: 3.4ms preprocess, 127.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 172.2ms\nSpeed: 3.2ms preprocess, 172.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 151.6ms\nSpeed: 3.1ms preprocess, 151.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 160.3ms\nSpeed: 2.8ms preprocess, 160.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 147.1ms\nSpeed: 3.1ms preprocess, 147.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 138.5ms\nSpeed: 3.3ms preprocess, 138.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 140.3ms\nSpeed: 3.5ms preprocess, 140.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 147.6ms\nSpeed: 3.8ms preprocess, 147.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 112.6ms\nSpeed: 2.6ms preprocess, 112.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 145.3ms\nSpeed: 4.3ms preprocess, 145.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 180.4ms\nSpeed: 2.9ms preprocess, 180.4ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 186.9ms\nSpeed: 5.3ms preprocess, 186.9ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 169.2ms\nSpeed: 3.1ms preprocess, 169.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 121.3ms\nSpeed: 2.7ms preprocess, 121.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 175.8ms\nSpeed: 2.8ms preprocess, 175.8ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 178.9ms\nSpeed: 4.1ms preprocess, 178.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 157.4ms\nSpeed: 3.1ms preprocess, 157.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 141.2ms\nSpeed: 2.5ms preprocess, 141.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 137.1ms\nSpeed: 3.7ms preprocess, 137.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 146.8ms\nSpeed: 3.2ms preprocess, 146.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 124.5ms\nSpeed: 3.0ms preprocess, 124.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 104.1ms\nSpeed: 2.8ms preprocess, 104.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n\n   \u26a1 FPS Stability:\n      Batch 1: 5.8 FPS\n      Batch 2: 5.8 FPS\n      Batch 3: 6.1 FPS\n      Variance: 3.1%\n"}, "teardown": {"duration": 0.0004978999495506287, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestSetup::test_imports", "lineno": 6, "outcome": "passed", "keywords": ["test_imports", "TestSetup", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.00038400012999773026, "outcome": "passed"}, "call": {"duration": 0.0003983997739851475, "outcome": "passed"}, "teardown": {"duration": 0.0003855000250041485, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestSetup::test_project_structure", "lineno": 13, "outcome": "passed", "keywords": ["test_project_structure", "TestSetup", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.00035350024700164795, "outcome": "passed"}, "call": {"duration": 0.0007222997955977917, "outcome": "passed"}, "teardown": {"duration": 0.0003780997358262539, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_file_exists", "lineno": 22, "outcome": "passed", "keywords": ["test_model_file_exists", "TestYOLOBasics", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003570001572370529, "outcome": "passed"}, "call": {"duration": 0.0005085999146103859, "outcome": "passed"}, "teardown": {"duration": 0.0003710002638399601, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_loads", "lineno": 31, "outcome": "passed", "keywords": ["test_model_loads", "TestYOLOBasics", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.00035690004006028175, "outcome": "passed"}, "call": {"duration": 0.08083359990268946, "outcome": "passed"}, "teardown": {"duration": 0.0004977998323738575, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_at_least_one_image_exists", "lineno": 39, "outcome": "passed", "keywords": ["test_at_least_one_image_exists", "TestDatasetMinimal", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.00044610025361180305, "outcome": "passed"}, "call": {"duration": 0.0009332001209259033, "outcome": "passed"}, "teardown": {"duration": 0.00042079994454979897, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_can_load_image", "lineno": 47, "outcome": "passed", "keywords": ["test_can_load_image", "TestDatasetMinimal", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003635999746620655, "outcome": "passed"}, "call": {"duration": 0.0065739997662603855, "outcome": "passed"}, "teardown": {"duration": 0.0003789002075791359, "outcome": "passed"}}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_detection_runs", "lineno": 57, "outcome": "passed", "keywords": ["test_detection_runs", "TestDatasetMinimal", "test_simple.py", "tests", "Yolo", ""], "setup": {"duration": 0.00034090038388967514, "outcome": "passed"}, "call": {"duration": 0.21097640041261911, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 86.5ms\nSpeed: 3.4ms preprocess, 86.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.0008950997143983841, "outcome": "passed"}}], "warnings": [{"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 19}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 76}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 146}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 200}, {"message": "Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_performance.py", "lineno": 20}, {"message": "Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_performance.py", "lineno": 88}, {"message": "Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_performance.py", "lineno": 219}, {"message": "Unknown pytest.mark.performance - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_performance.py", "lineno": 256}, {"message": "Unknown pytest.mark.regression - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_regression.py", "lineno": 23}, {"message": "Unknown pytest.mark.regression - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_regression.py", "lineno": 112}, {"message": "Unknown pytest.mark.regression - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_regression.py", "lineno": 251}, {"message": "Unknown pytest.mark.regression - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_regression.py", "lineno": 293}]}