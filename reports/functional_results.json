{"created": 1767622361.648336, "duration": 10.875247478485107, "exitcode": 0, "root": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo", "environment": {}, "summary": {"passed": 10, "total": 10, "collected": 32, "deselected": 22}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": ".", "type": "Dir"}]}, {"nodeid": "assets", "outcome": "passed", "result": []}, {"nodeid": "configs", "outcome": "passed", "result": []}, {"nodeid": "dashboard", "outcome": "passed", "result": []}, {"nodeid": "data/images/edge_cases", "outcome": "passed", "result": []}, {"nodeid": "data/images/normal", "outcome": "passed", "result": []}, {"nodeid": "data/images", "outcome": "passed", "result": [{"nodeid": "data/images/edge_cases", "type": "Dir"}, {"nodeid": "data/images/normal", "type": "Dir"}]}, {"nodeid": "data/videos", "outcome": "passed", "result": []}, {"nodeid": "data", "outcome": "passed", "result": [{"nodeid": "data/images", "type": "Dir"}, {"nodeid": "data/videos", "type": "Dir"}]}, {"nodeid": "models", "outcome": "passed", "result": []}, {"nodeid": "reports", "outcome": "passed", "result": []}, {"nodeid": "res_images/edge_cases", "outcome": "passed", "result": []}, {"nodeid": "res_images/normal", "outcome": "passed", "result": []}, {"nodeid": "res_images", "outcome": "passed", "result": [{"nodeid": "res_images/edge_cases", "type": "Dir"}, {"nodeid": "res_images/normal", "type": "Dir"}]}, {"nodeid": "scripts", "outcome": "passed", "result": []}, {"nodeid": "src/models", "outcome": "passed", "result": []}, {"nodeid": "src/reports", "outcome": "passed", "result": []}, {"nodeid": "src", "outcome": "passed", "result": [{"nodeid": "src/models", "type": "Dir"}, {"nodeid": "src/reports", "type": "Dir"}]}, {"nodeid": "tests/models", "outcome": "passed", "result": []}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_on_known_image", "type": "Function", "lineno": 27}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_result_format", "type": "Function", "lineno": 42}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_confidence_threshold_works", "type": "Function", "lineno": 58}]}, {"nodeid": "tests/test_functional.py::TestDatasetDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_normal_dataset", "type": "Function", "lineno": 84}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_edge_cases_dataset", "type": "Function", "lineno": 107}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_inference_time_reasonable", "type": "Function", "lineno": 127}]}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_detect_by_category", "type": "Function", "lineno": 153}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_compare_normal_vs_edge_cases", "type": "Function", "lineno": 172}]}, {"nodeid": "tests/test_functional.py::TestResultsSaving", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_creates_file", "type": "Function", "lineno": 207}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_json_format", "type": "Function", "lineno": 220}]}, {"nodeid": "tests/test_functional.py", "outcome": "passed", "result": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestDatasetDetection", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory", "type": "Class"}, {"nodeid": "tests/test_functional.py::TestResultsSaving", "type": "Class"}]}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_cold_start_latency", "type": "Function", "lineno": 27, "deselected": true}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_warm_inference_latency", "type": "Function", "lineno": 41, "deselected": true}, {"nodeid": "tests/test_performance.py::TestLatencyPerformance::test_latency_variance", "type": "Function", "lineno": 67, "deselected": true}]}, {"nodeid": "tests/test_performance.py::TestResourceUsage", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestResourceUsage::test_cpu_usage_during_inference", "type": "Function", "lineno": 95, "deselected": true}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_memory_usage", "type": "Function", "lineno": 129, "deselected": true}, {"nodeid": "tests/test_performance.py::TestResourceUsage::test_gpu_availability_check", "type": "Function", "lineno": 149, "deselected": true}]}, {"nodeid": "tests/test_performance.py::TestFPSRealTime", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestFPSRealTime::test_sustained_fps", "type": "Function", "lineno": 173, "deselected": true}, {"nodeid": "tests/test_performance.py::TestFPSRealTime::test_batch_vs_single_inference", "type": "Function", "lineno": 192, "deselected": true}]}, {"nodeid": "tests/test_performance.py::TestModelBenchmarking", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestModelBenchmarking::test_yolov8_model_variants", "type": "Function", "lineno": 222, "deselected": true}]}, {"nodeid": "tests/test_performance.py::TestSystemInfo", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestSystemInfo::test_collect_system_info", "type": "Function", "lineno": 259, "deselected": true}]}, {"nodeid": "tests/test_performance.py", "outcome": "passed", "result": [{"nodeid": "tests/test_performance.py::TestLatencyPerformance", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestResourceUsage", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestFPSRealTime", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestModelBenchmarking", "type": "Class"}, {"nodeid": "tests/test_performance.py::TestSystemInfo", "type": "Class"}]}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_baseline_or_regression", "type": "Function", "lineno": 144, "deselected": true}, {"nodeid": "tests/test_regression.py::TestRegressionMetrics::test_accuracy_consistency", "type": "Function", "lineno": 230, "deselected": true}]}, {"nodeid": "tests/test_regression.py::TestVersionComparison", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestVersionComparison::test_compare_model_versions", "type": "Function", "lineno": 254, "deselected": true}]}, {"nodeid": "tests/test_regression.py::TestDegradationDetection", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestDegradationDetection::test_no_memory_leak", "type": "Function", "lineno": 296, "deselected": true}, {"nodeid": "tests/test_regression.py::TestDegradationDetection::test_fps_stability_over_time", "type": "Function", "lineno": 319, "deselected": true}]}, {"nodeid": "tests/test_regression.py", "outcome": "passed", "result": [{"nodeid": "tests/test_regression.py::TestRegressionMetrics", "type": "Class"}, {"nodeid": "tests/test_regression.py::TestVersionComparison", "type": "Class"}, {"nodeid": "tests/test_regression.py::TestDegradationDetection", "type": "Class"}]}, {"nodeid": "tests/test_simple.py::TestSetup", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestSetup::test_imports", "type": "Function", "lineno": 6, "deselected": true}, {"nodeid": "tests/test_simple.py::TestSetup::test_project_structure", "type": "Function", "lineno": 13, "deselected": true}]}, {"nodeid": "tests/test_simple.py::TestYOLOBasics", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_file_exists", "type": "Function", "lineno": 22, "deselected": true}, {"nodeid": "tests/test_simple.py::TestYOLOBasics::test_model_loads", "type": "Function", "lineno": 31, "deselected": true}]}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_at_least_one_image_exists", "type": "Function", "lineno": 39, "deselected": true}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_can_load_image", "type": "Function", "lineno": 47, "deselected": true}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal::test_detection_runs", "type": "Function", "lineno": 57, "deselected": true}]}, {"nodeid": "tests/test_simple.py", "outcome": "passed", "result": [{"nodeid": "tests/test_simple.py::TestSetup", "type": "Class"}, {"nodeid": "tests/test_simple.py::TestYOLOBasics", "type": "Class"}, {"nodeid": "tests/test_simple.py::TestDatasetMinimal", "type": "Class"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/models", "type": "Dir"}, {"nodeid": "tests/test_functional.py", "type": "Module"}, {"nodeid": "tests/test_performance.py", "type": "Module"}, {"nodeid": "tests/test_regression.py", "type": "Module"}, {"nodeid": "tests/test_simple.py", "type": "Module"}]}, {"nodeid": ".", "outcome": "passed", "result": [{"nodeid": "assets", "type": "Dir"}, {"nodeid": "configs", "type": "Dir"}, {"nodeid": "dashboard", "type": "Dir"}, {"nodeid": "data", "type": "Dir"}, {"nodeid": "models", "type": "Dir"}, {"nodeid": "reports", "type": "Dir"}, {"nodeid": "res_images", "type": "Dir"}, {"nodeid": "scripts", "type": "Dir"}, {"nodeid": "src", "type": "Dir"}, {"nodeid": "tests", "type": "Dir"}]}], "tests": [{"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_on_known_image", "lineno": 27, "outcome": "passed", "keywords": ["test_detection_on_known_image", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.056313599925488234, "outcome": "passed"}, "call": {"duration": 0.1676456001587212, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 84.2ms\nSpeed: 3.3ms preprocess, 84.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.00032560015097260475, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_detection_result_format", "lineno": 42, "outcome": "passed", "keywords": ["test_detection_result_format", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.00029349979013204575, "outcome": "passed"}, "call": {"duration": 0.08506610011681914, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 75.3ms\nSpeed: 2.4ms preprocess, 75.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.00036769965663552284, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestSingleImageDetection::test_confidence_threshold_works", "lineno": 58, "outcome": "passed", "keywords": ["test_confidence_threshold_works", "TestSingleImageDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.00035299966111779213, "outcome": "passed"}, "call": {"duration": 0.16294539999216795, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 2 couchs, 2 remotes, 78.9ms\nSpeed: 1.5ms preprocess, 78.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 480x640 2 cats, 65.8ms\nSpeed: 2.0ms preprocess, 65.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"}, "teardown": {"duration": 0.0003766999579966068, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_normal_dataset", "lineno": 84, "outcome": "passed", "keywords": ["test_detection_on_normal_dataset", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.04724639980122447, "outcome": "passed"}, "call": {"duration": 0.42581319995224476, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 79.9ms\nSpeed: 2.5ms preprocess, 79.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 71.7ms\nSpeed: 2.6ms preprocess, 71.7ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 61.8ms\nSpeed: 2.5ms preprocess, 61.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 76.3ms\nSpeed: 2.2ms preprocess, 76.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 58.4ms\nSpeed: 2.5ms preprocess, 58.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u2705 5 images trait\u00e9es\n   \u2705 5/5 avec d\u00e9tections (100.0%)\n"}, "teardown": {"duration": 0.0002652001567184925, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_detection_on_edge_cases_dataset", "lineno": 107, "outcome": "passed", "keywords": ["test_detection_on_edge_cases_dataset", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0004575001075863838, "outcome": "passed"}, "call": {"duration": 1.8779095001518726, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 79.0ms\nSpeed: 2.1ms preprocess, 79.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 1 donut, 59.5ms\nSpeed: 2.6ms preprocess, 59.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 58.3ms\nSpeed: 1.9ms preprocess, 58.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 2 cups, 1 toilet, 59.5ms\nSpeed: 1.9ms preprocess, 59.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 59.3ms\nSpeed: 1.9ms preprocess, 59.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 65.4ms\nSpeed: 2.0ms preprocess, 65.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 61.2ms\nSpeed: 2.7ms preprocess, 61.2ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 60.1ms\nSpeed: 1.9ms preprocess, 60.1ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 66.8ms\nSpeed: 2.0ms preprocess, 66.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 1 sink, 62.3ms\nSpeed: 2.0ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 dogs, 1 remote, 64.5ms\nSpeed: 2.1ms preprocess, 64.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 1 dining table, 1 refrigerator, 65.3ms\nSpeed: 2.6ms preprocess, 65.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 74.7ms\nSpeed: 2.0ms preprocess, 74.7ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 (no detections), 72.5ms\nSpeed: 2.2ms preprocess, 72.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 80.6ms\nSpeed: 2.1ms preprocess, 80.6ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 2 remotes, 67.2ms\nSpeed: 2.0ms preprocess, 67.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 (no detections), 62.9ms\nSpeed: 2.6ms preprocess, 62.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 81.5ms\nSpeed: 1.9ms preprocess, 81.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 (no detections), 64.6ms\nSpeed: 1.8ms preprocess, 64.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 (no detections), 61.4ms\nSpeed: 1.9ms preprocess, 61.4ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 480x640 2 cats, 1 remote, 66.2ms\nSpeed: 2.0ms preprocess, 66.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 77.4ms\nSpeed: 2.7ms preprocess, 77.4ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 62.8ms\nSpeed: 1.9ms preprocess, 62.8ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 4 toilets, 63.9ms\nSpeed: 2.0ms preprocess, 63.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 1 sink, 64.0ms\nSpeed: 1.9ms preprocess, 64.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u2705 25 edge cases trait\u00e9es\n   \u2705 79 d\u00e9tections au total\n   \u26a0\ufe0f  76.0% avec d\u00e9tections (d\u00e9gradation attendue)\n"}, "teardown": {"duration": 0.00033590011298656464, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetDetection::test_inference_time_reasonable", "lineno": 127, "outcome": "passed", "keywords": ["test_inference_time_reasonable", "TestDatasetDetection", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.000353899784386158, "outcome": "passed"}, "call": {"duration": 0.3827228997834027, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 90.0ms\nSpeed: 2.9ms preprocess, 90.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 60.8ms\nSpeed: 2.7ms preprocess, 60.8ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 60.3ms\nSpeed: 2.4ms preprocess, 60.3ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 61.1ms\nSpeed: 1.8ms preprocess, 61.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 60.6ms\nSpeed: 1.8ms preprocess, 60.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n   \u23f1\ufe0f  Temps moyen : 72.47ms\n   \u23f1\ufe0f  Temps max : 96.73ms\n"}, "teardown": {"duration": 0.0003754999488592148, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_detect_by_category", "lineno": 153, "outcome": "passed", "keywords": ["test_detect_by_category", "TestDatasetByCategory", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.05978839984163642, "outcome": "passed"}, "call": {"duration": 2.0942677999846637, "outcome": "passed", "stdout": "\n\ud83d\udcc2 Traitement par cat\u00e9gorie...\n   Base : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\n   Cat\u00e9gories trouv\u00e9es : 2\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : EDGE_CASES\n============================================================\n\n\ud83d\udcca Traitement de 25 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\edge_cases\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 67.1ms\nSpeed: 2.2ms preprocess, 67.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n[1/25] blur_cats_sofa.jpg             \u2192  2 objets ( 99.41ms)\n\n0: 448x640 1 donut, 60.1ms\nSpeed: 2.5ms preprocess, 60.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n[2/25] blur_kitchen.jpg               \u2192  1 objets ( 64.98ms)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 58.0ms\nSpeed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n[3/25] blur_person_kitchen.jpg        \u2192  5 objets ( 63.38ms)\n\n0: 640x448 2 cups, 1 toilet, 72.0ms\nSpeed: 1.9ms preprocess, 72.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n[4/25] blur_toilet.jpg                \u2192  3 objets ( 76.92ms)\n\n0: 448x640 (no detections), 59.5ms\nSpeed: 1.8ms preprocess, 59.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[5/25] blur_washbasin.jpg             \u2192  0 objets ( 62.61ms)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 63.5ms\nSpeed: 2.0ms preprocess, 63.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n[6/25] dark_cats_sofa.jpg             \u2192  5 objets ( 69.01ms)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 59.1ms\nSpeed: 2.5ms preprocess, 59.1ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n[7/25] dark_kitchen.jpg               \u2192  8 objets ( 65.55ms)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 58.7ms\nSpeed: 1.8ms preprocess, 58.7ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n[8/25] dark_person_kitchen.jpg        \u2192 10 objets ( 65.31ms)\n\n0: 640x448 1 toilet, 60.7ms\nSpeed: 1.8ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n[9/25] dark_toilet.jpg                \u2192  1 objets ( 64.98ms)\n\n0: 448x640 1 sink, 58.1ms\nSpeed: 1.8ms preprocess, 58.1ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n[10/25] dark_washbasin.jpg             \u2192  1 objets ( 61.93ms)\n\n0: 480x640 2 dogs, 1 remote, 63.2ms\nSpeed: 2.3ms preprocess, 63.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[11/25] lowres_cats_sofa.jpg           \u2192  3 objets ( 68.69ms)\n\n0: 448x640 1 dining table, 1 refrigerator, 59.1ms\nSpeed: 2.5ms preprocess, 59.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[12/25] lowres_kitchen.jpg             \u2192  2 objets ( 63.79ms)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 59.5ms\nSpeed: 1.8ms preprocess, 59.5ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n[13/25] lowres_person_kitchen.jpg      \u2192  8 objets ( 65.68ms)\n\n0: 640x448 (no detections), 60.2ms\nSpeed: 1.8ms preprocess, 60.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n[14/25] lowres_toilet.jpg              \u2192  0 objets ( 63.31ms)\n\n0: 448x640 (no detections), 60.2ms\nSpeed: 1.9ms preprocess, 60.2ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n[15/25] lowres_washbasin.jpg           \u2192  0 objets ( 63.32ms)\n\n0: 480x640 2 cats, 2 remotes, 64.1ms\nSpeed: 2.0ms preprocess, 64.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[16/25] noisy_cats_sofa.jpg            \u2192  4 objets ( 69.37ms)\n\n0: 448x640 (no detections), 59.6ms\nSpeed: 2.5ms preprocess, 59.6ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n[17/25] noisy_kitchen.jpg              \u2192  0 objets ( 63.10ms)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 59.1ms\nSpeed: 1.8ms preprocess, 59.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[18/25] noisy_person_kitchen.jpg       \u2192  6 objets ( 64.48ms)\n\n0: 640x448 (no detections), 70.3ms\nSpeed: 1.8ms preprocess, 70.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n[19/25] noisy_toilet.jpg               \u2192  0 objets ( 73.34ms)\n\n0: 448x640 (no detections), 59.5ms\nSpeed: 1.9ms preprocess, 59.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[20/25] noisy_washbasin.jpg            \u2192  0 objets ( 62.62ms)\n\n0: 480x640 2 cats, 1 remote, 60.7ms\nSpeed: 1.5ms preprocess, 60.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n[21/25] rotated_cats_sofa.jpg          \u2192  3 objets ( 64.39ms)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 60.3ms\nSpeed: 2.4ms preprocess, 60.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n[22/25] rotated_kitchen.jpg            \u2192  7 objets ( 66.52ms)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 59.6ms\nSpeed: 1.8ms preprocess, 59.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n[23/25] rotated_person_kitchen.jpg     \u2192  5 objets ( 64.76ms)\n\n0: 640x448 4 toilets, 60.7ms\nSpeed: 1.8ms preprocess, 60.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[24/25] rotated_toilet.jpg             \u2192  4 objets ( 65.32ms)\n\n0: 448x640 1 sink, 59.4ms\nSpeed: 1.8ms preprocess, 59.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[25/25] rotated_washbasin.jpg          \u2192  1 objets ( 63.75ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 25\nD\u00e9tections totales    : 79\nD\u00e9tections par image  : 3.16\nTemps moyen           : 67.06ms\nTemps min/max         : 61.93ms / 99.41ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : NORMAL\n============================================================\n\n\ud83d\udcca Traitement de 5 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\normal\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 61.8ms\nSpeed: 2.0ms preprocess, 61.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n[1/5] cats_sofa.jpg                  \u2192  5 objets ( 67.33ms)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 58.7ms\nSpeed: 2.5ms preprocess, 58.7ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n[2/5] kitchen.jpg                    \u2192 10 objets ( 65.82ms)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 58.7ms\nSpeed: 1.9ms preprocess, 58.7ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n[3/5] person_kitchen.jpg             \u2192  9 objets ( 64.86ms)\n\n0: 640x448 1 toilet, 60.0ms\nSpeed: 1.8ms preprocess, 60.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n[4/5] toilet.jpg                     \u2192  1 objets ( 64.22ms)\n\n0: 448x640 2 sinks, 63.4ms\nSpeed: 1.9ms preprocess, 63.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n[5/5] washbasin.jpg                  \u2192  2 objets ( 67.98ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 5\nD\u00e9tections totales    : 27\nD\u00e9tections par image  : 5.40\nTemps moyen           : 66.04ms\nTemps min/max         : 64.22ms / 67.98ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcca R\u00c9SUM\u00c9 GLOBAL\n============================================================\nedge_cases           :  25 images,   79 d\u00e9tections, moy=67.06ms\nnormal               :   5 images,   27 d\u00e9tections, moy=66.04ms\n\n   \ud83d\udcc2 Cat\u00e9gories trouv\u00e9es : ['edge_cases', 'normal']\n   \u2705 edge_cases      : 25 images, 79 d\u00e9tections\n   \u2705 normal          : 5 images, 27 d\u00e9tections\n"}, "teardown": {"duration": 0.00033139996230602264, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestDatasetByCategory::test_compare_normal_vs_edge_cases", "lineno": 172, "outcome": "passed", "keywords": ["test_compare_normal_vs_edge_cases", "TestDatasetByCategory", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0003440999425947666, "outcome": "passed"}, "call": {"duration": 2.235361299943179, "outcome": "passed", "stdout": "\n\ud83d\udcc2 Traitement par cat\u00e9gorie...\n   Base : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\n   Cat\u00e9gories trouv\u00e9es : 2\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : EDGE_CASES\n============================================================\n\n\ud83d\udcca Traitement de 25 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\edge_cases\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 79.3ms\nSpeed: 1.9ms preprocess, 79.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n[1/25] blur_cats_sofa.jpg             \u2192  2 objets ( 83.56ms)\n\n0: 448x640 1 donut, 62.8ms\nSpeed: 2.7ms preprocess, 62.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n[2/25] blur_kitchen.jpg               \u2192  1 objets ( 67.89ms)\n\n0: 448x640 3 persons, 1 broccoli, 1 chair, 66.8ms\nSpeed: 1.9ms preprocess, 66.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n[3/25] blur_person_kitchen.jpg        \u2192  5 objets ( 72.17ms)\n\n0: 640x448 2 cups, 1 toilet, 62.3ms\nSpeed: 1.9ms preprocess, 62.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[4/25] blur_toilet.jpg                \u2192  3 objets ( 67.08ms)\n\n0: 448x640 (no detections), 62.1ms\nSpeed: 1.9ms preprocess, 62.1ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n[5/25] blur_washbasin.jpg             \u2192  0 objets ( 65.29ms)\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 69.8ms\nSpeed: 2.0ms preprocess, 69.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n[6/25] dark_cats_sofa.jpg             \u2192  5 objets ( 75.59ms)\n\n0: 448x640 3 oranges, 1 dining table, 1 oven, 3 refrigerators, 73.6ms\nSpeed: 2.6ms preprocess, 73.6ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n[7/25] dark_kitchen.jpg               \u2192  8 objets ( 81.39ms)\n\n0: 448x640 1 person, 2 cups, 4 bowls, 1 potted plant, 1 dining table, 1 oven, 70.4ms\nSpeed: 2.3ms preprocess, 70.4ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n[8/25] dark_person_kitchen.jpg        \u2192 10 objets ( 77.74ms)\n\n0: 640x448 1 toilet, 80.3ms\nSpeed: 2.0ms preprocess, 80.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n[9/25] dark_toilet.jpg                \u2192  1 objets ( 85.03ms)\n\n0: 448x640 1 sink, 66.2ms\nSpeed: 2.3ms preprocess, 66.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n[10/25] dark_washbasin.jpg             \u2192  1 objets ( 71.15ms)\n\n0: 480x640 2 dogs, 1 remote, 67.7ms\nSpeed: 2.1ms preprocess, 67.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[11/25] lowres_cats_sofa.jpg           \u2192  3 objets ( 73.25ms)\n\n0: 448x640 1 dining table, 1 refrigerator, 72.6ms\nSpeed: 2.6ms preprocess, 72.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n[12/25] lowres_kitchen.jpg             \u2192  2 objets ( 78.34ms)\n\n0: 448x640 2 persons, 2 bottles, 1 bowl, 1 pizza, 1 dining table, 1 clock, 83.9ms\nSpeed: 2.1ms preprocess, 83.9ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n[13/25] lowres_person_kitchen.jpg      \u2192  8 objets ( 90.45ms)\n\n0: 640x448 (no detections), 62.4ms\nSpeed: 1.8ms preprocess, 62.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n[14/25] lowres_toilet.jpg              \u2192  0 objets ( 65.49ms)\n\n0: 448x640 (no detections), 63.6ms\nSpeed: 2.1ms preprocess, 63.6ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[15/25] lowres_washbasin.jpg           \u2192  0 objets ( 66.91ms)\n\n0: 480x640 2 cats, 2 remotes, 83.9ms\nSpeed: 2.2ms preprocess, 83.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n[16/25] noisy_cats_sofa.jpg            \u2192  4 objets ( 89.48ms)\n\n0: 448x640 (no detections), 65.5ms\nSpeed: 2.5ms preprocess, 65.5ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[17/25] noisy_kitchen.jpg              \u2192  0 objets ( 69.25ms)\n\n0: 448x640 2 persons, 1 cup, 2 bowls, 1 dining table, 62.5ms\nSpeed: 1.9ms preprocess, 62.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[18/25] noisy_person_kitchen.jpg       \u2192  6 objets ( 68.09ms)\n\n0: 640x448 (no detections), 66.7ms\nSpeed: 2.2ms preprocess, 66.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n[19/25] noisy_toilet.jpg               \u2192  0 objets ( 70.23ms)\n\n0: 448x640 (no detections), 65.3ms\nSpeed: 2.2ms preprocess, 65.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n[20/25] noisy_washbasin.jpg            \u2192  0 objets ( 68.78ms)\n\n0: 480x640 2 cats, 1 remote, 62.1ms\nSpeed: 1.4ms preprocess, 62.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n[21/25] rotated_cats_sofa.jpg          \u2192  3 objets ( 66.54ms)\n\n0: 448x640 4 oranges, 1 dining table, 1 oven, 1 refrigerator, 58.9ms\nSpeed: 2.5ms preprocess, 58.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n[22/25] rotated_kitchen.jpg            \u2192  7 objets ( 65.10ms)\n\n0: 448x640 2 persons, 1 bowl, 2 ovens, 56.3ms\nSpeed: 1.5ms preprocess, 56.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n[23/25] rotated_person_kitchen.jpg     \u2192  5 objets ( 60.98ms)\n\n0: 640x448 4 toilets, 58.7ms\nSpeed: 1.8ms preprocess, 58.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n[24/25] rotated_toilet.jpg             \u2192  4 objets ( 63.43ms)\n\n0: 448x640 1 sink, 59.4ms\nSpeed: 1.9ms preprocess, 59.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n[25/25] rotated_washbasin.jpg          \u2192  1 objets ( 63.43ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 25\nD\u00e9tections totales    : 79\nD\u00e9tections par image  : 3.16\nTemps moyen           : 72.27ms\nTemps min/max         : 60.98ms / 90.45ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcc1 CAT\u00c9GORIE : NORMAL\n============================================================\n\n\ud83d\udcca Traitement de 5 images...\n\ud83d\udcc1 Dossier : C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\data\\images\\normal\n\ud83c\udfaf Seuil de confiance : 0.25\n\n\n0: 480x640 2 cats, 1 couch, 2 remotes, 62.5ms\nSpeed: 1.9ms preprocess, 62.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n[1/5] cats_sofa.jpg                  \u2192  5 objets ( 67.96ms)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 62.6ms\nSpeed: 2.5ms preprocess, 62.6ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n[2/5] kitchen.jpg                    \u2192 10 objets ( 69.19ms)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 59.9ms\nSpeed: 1.8ms preprocess, 59.9ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n[3/5] person_kitchen.jpg             \u2192  9 objets ( 66.08ms)\n\n0: 640x448 1 toilet, 60.0ms\nSpeed: 1.9ms preprocess, 60.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n[4/5] toilet.jpg                     \u2192  1 objets ( 64.35ms)\n\n0: 448x640 2 sinks, 68.7ms\nSpeed: 1.8ms preprocess, 68.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n[5/5] washbasin.jpg                  \u2192  2 objets ( 73.26ms)\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcca R\u00c9SUM\u00c9\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nImages trait\u00e9es       : 5\nD\u00e9tections totales    : 27\nD\u00e9tections par image  : 5.40\nTemps moyen           : 68.17ms\nTemps min/max         : 64.35ms / 73.26ms\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\n============================================================\n\ud83d\udcca R\u00c9SUM\u00c9 GLOBAL\n============================================================\nedge_cases           :  25 images,   79 d\u00e9tections, moy=72.27ms\nnormal               :   5 images,   27 d\u00e9tections, moy=68.17ms\n\n   \ud83d\udcca D\u00e9tections par image :\n      Normal     : 5.40\n      Edge cases : 3.16\n      D\u00e9gradation: 41.5%\n"}, "teardown": {"duration": 0.0004014996811747551, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_creates_file", "lineno": 207, "outcome": "passed", "keywords": ["test_save_results_creates_file", "TestResultsSaving", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.06533630006015301, "outcome": "passed"}, "call": {"duration": 0.3746704999357462, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 64.5ms\nSpeed: 2.2ms preprocess, 64.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 60.2ms\nSpeed: 2.3ms preprocess, 60.2ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 58.2ms\nSpeed: 1.8ms preprocess, 58.2ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 59.8ms\nSpeed: 1.6ms preprocess, 59.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 59.0ms\nSpeed: 1.9ms preprocess, 59.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n\u2705 R\u00e9sultats sauvegard\u00e9s : C:\\Users\\hp\\AppData\\Local\\Temp\\pytest-of-hp\\pytest-10\\test_save_results_creates_file0\\test_results.json\n   - 5 images trait\u00e9es\n   - 27 d\u00e9tections au total\n"}, "teardown": {"duration": 0.0003667999990284443, "outcome": "passed"}}, {"nodeid": "tests/test_functional.py::TestResultsSaving::test_save_results_json_format", "lineno": 220, "outcome": "passed", "keywords": ["test_save_results_json_format", "TestResultsSaving", "functional", "test_functional.py", "tests", "Yolo", ""], "setup": {"duration": 0.0020239995792508125, "outcome": "passed"}, "call": {"duration": 0.37272540014237165, "outcome": "passed", "stdout": "\n0: 480x640 2 cats, 1 couch, 2 remotes, 73.3ms\nSpeed: 2.1ms preprocess, 73.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n\n0: 448x640 6 oranges, 1 dining table, 1 oven, 2 refrigerators, 59.1ms\nSpeed: 2.5ms preprocess, 59.1ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 448x640 2 persons, 1 cup, 4 bowls, 1 potted plant, 1 oven, 58.3ms\nSpeed: 2.3ms preprocess, 58.3ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n\n0: 640x448 1 toilet, 58.0ms\nSpeed: 1.8ms preprocess, 58.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n\n0: 448x640 2 sinks, 61.0ms\nSpeed: 1.8ms preprocess, 61.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n\n\u2705 R\u00e9sultats sauvegard\u00e9s : C:\\Users\\hp\\AppData\\Local\\Temp\\pytest-of-hp\\pytest-10\\test_save_results_json_format0\\test_results.json\n   - 5 images trait\u00e9es\n   - 27 d\u00e9tections au total\n\n   \u2705 JSON valide avec 5 images\n"}, "teardown": {"duration": 0.000551499892026186, "outcome": "passed"}}], "warnings": [{"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 19}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 76}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 146}, {"message": "Unknown pytest.mark.functional - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html", "category": "PytestUnknownMarkWarning", "when": "collect", "filename": "C:\\Users\\hp\\OneDrive\\Documents\\my_projects\\Yolo\\tests\\test_functional.py", "lineno": 200}]}