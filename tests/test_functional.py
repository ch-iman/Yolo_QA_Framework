"""
Tests fonctionnels pour valider le comportement de YOLO sur dataset.

Ces tests v√©rifient que :
- Les d√©tections sont correctes sur images individuelles
- Le traitement de dataset complet fonctionne
- Les edge cases sont g√©r√©s correctement
- Les r√©sultats peuvent √™tre sauvegard√©s

Ex√©cution : pytest tests/test_functional.py -v
Dur√©e attendue : 10-30 secondes (selon taille dataset)
"""

import pytest
from pathlib import Path
from src.yolo_detector import YOLODetector
import json


class TestSingleImageDetection:
    """Tests sur image unique (basiques)"""
    
    @pytest.fixture(scope="class")
    def detector(self):
        """Fixture : cr√©e un d√©tecteur une fois pour toute la classe"""
        return YOLODetector()
    
    def test_detection_on_known_image(self, detector, sample_image_path):
        """D√©tecte des objets sur une image connue"""
        result = detector.detect(sample_image_path)
        
        # Doit d√©tecter au moins quelque chose (peut √™tre 0 sur certaines images)
        assert result['num_detections'] >= 0, "num_detections doit √™tre >= 0"
        
        # Si d√©tections pr√©sentes, v√©rifier leur format
        if result['num_detections'] > 0:
            det = result['detections'][0]
            assert 'class_name' in det, "D√©tection doit avoir 'class_name'"
            assert 'confidence' in det, "D√©tection doit avoir 'confidence'"
            assert 'bbox' in det, "D√©tection doit avoir 'bbox'"
            assert len(det['bbox']) == 4, "bbox doit avoir 4 coordonn√©es [x1,y1,x2,y2]"
    
    def test_detection_result_format(self, detector, sample_image_path):
        """V√©rifie le format complet du r√©sultat"""
        result = detector.detect(sample_image_path)
        
        # Cl√©s requises
        required_keys = ['image_path', 'detections', 'inference_time', 
                        'image_shape', 'num_detections']
        for key in required_keys:
            assert key in result, f"Cl√© '{key}' manquante dans le r√©sultat"
        
        # Types corrects
        assert isinstance(result['detections'], list)
        assert isinstance(result['inference_time'], float)
        assert isinstance(result['num_detections'], int)
        assert result['inference_time'] > 0, "Temps d'inf√©rence doit √™tre > 0"
    
    def test_confidence_threshold_works(self, detector, sample_image_path):
        """V√©rifie que le seuil de confiance fonctionne"""
        # Seuil bas
        result_low = detector.detect(sample_image_path, conf_threshold=0.1)
        
        # Seuil haut
        result_high = detector.detect(sample_image_path, conf_threshold=0.8)
        
        # Seuil bas doit donner >= d√©tections que seuil haut
        assert result_low['num_detections'] >= result_high['num_detections'], \
            "Seuil 0.1 devrait donner plus ou autant de d√©tections que 0.8"
        
        # V√©rifier que toutes les d√©tections respectent le seuil haut
        for det in result_high['detections']:
            assert det['confidence'] >= 0.8, \
                f"D√©tection avec confidence {det['confidence']} < 0.8"


class TestDatasetDetection:
    """Tests sur dataset complet"""
    
    @pytest.fixture(scope="class")
    def detector(self):
        """Fixture : d√©tecteur pour toute la classe"""
        return YOLODetector()
    
    def test_detection_on_normal_dataset(self, detector, dataset_normal_path):
        """Test sur TOUTES les images normales"""
        results = detector.detect_on_dataset(dataset_normal_path, verbose=False)
        
        # Au moins 1 image trait√©e
        assert len(results) > 0, "Aucune image trait√©e dans le dataset normal"
        
        # Toutes les images doivent avoir un r√©sultat valide
        for result in results:
            assert 'image_path' in result
            assert 'num_detections' in result
            assert 'inference_time' in result
        
        # Au moins 80% des images normales devraient avoir des d√©tections
        images_with_detections = sum(1 for r in results if r['num_detections'] > 0)
        detection_rate = images_with_detections / len(results)
        
        assert detection_rate >= 0.8, \
            f"Seulement {detection_rate*100:.1f}% des images ont des d√©tections (attendu >= 80%)"
        
        print(f"\n   ‚úÖ {len(results)} images trait√©es")
        print(f"   ‚úÖ {images_with_detections}/{len(results)} avec d√©tections ({detection_rate*100:.1f}%)")
    
    def test_detection_on_edge_cases_dataset(self, detector, dataset_edge_cases_path):
        """Test sur edge cases (images d√©grad√©es)"""
        results = detector.detect_on_dataset(dataset_edge_cases_path, verbose=False)
        
        # Au moins quelques images trait√©es
        assert len(results) > 0, "Aucune image edge case trait√©e"
        
        # M√™me sur edge cases, on attend QUELQUES d√©tections (pas 0 partout)
        total_detections = sum(r['num_detections'] for r in results)
        assert total_detections > 0, \
            "Aucune d√©tection sur AUCUN edge case (trop s√©v√®re)"
        
        # Mais on accepte que certaines images n'aient pas de d√©tections
        images_with_detections = sum(1 for r in results if r['num_detections'] > 0)
        detection_rate = images_with_detections / len(results)
        
        print(f"\n   ‚úÖ {len(results)} edge cases trait√©es")
        print(f"   ‚úÖ {total_detections} d√©tections au total")
        print(f"   ‚ö†Ô∏è  {detection_rate*100:.1f}% avec d√©tections (d√©gradation attendue)")
    
    def test_inference_time_reasonable(self, detector, dataset_normal_path):
        """V√©rifie que les temps d'inf√©rence sont raisonnables"""
        results = detector.detect_on_dataset(dataset_normal_path, verbose=False)
        
        # Calculer temps moyen
        avg_time = sum(r['inference_time'] for r in results) / len(results)
        max_time = max(r['inference_time'] for r in results)
        
        # Sur CPU, on accepte jusqu'√† 500ms par image
        assert avg_time < 0.5, \
            f"Temps moyen trop √©lev√© : {avg_time*1000:.2f}ms (max attendu: 500ms)"
        
        assert max_time < 1.0, \
            f"Temps maximum trop √©lev√© : {max_time*1000:.2f}ms (max attendu: 1000ms)"
        
        print(f"\n   ‚è±Ô∏è  Temps moyen : {avg_time*1000:.2f}ms")
        print(f"   ‚è±Ô∏è  Temps max : {max_time*1000:.2f}ms")


class TestDatasetByCategory:
    """Tests de traitement par cat√©gories"""
    
    @pytest.fixture(scope="class")
    def detector(self):
        return YOLODetector()
    
    def test_detect_by_category(self, detector, project_paths):
        """Test traitement par cat√©gories (normal + edge_cases)"""
        base_dir = project_paths['data'] / 'images'
        
        results_by_cat = detector.detect_on_dataset_by_category(str(base_dir))
        
        # Au moins 1 cat√©gorie trouv√©e
        assert len(results_by_cat) > 0, "Aucune cat√©gorie trouv√©e"
        
        # Cat√©gorie "normal" doit exister
        assert 'normal' in results_by_cat, "Cat√©gorie 'normal' manquante"
        assert len(results_by_cat['normal']) > 0, "Aucune image dans 'normal'"
        
        # Afficher r√©sum√©
        print(f"\n   üìÇ Cat√©gories trouv√©es : {list(results_by_cat.keys())}")
        for cat, results in results_by_cat.items():
            total = sum(r['num_detections'] for r in results)
            print(f"   ‚úÖ {cat:15s} : {len(results)} images, {total} d√©tections")
    
    def test_compare_normal_vs_edge_cases(self, detector, project_paths):
        """Compare les d√©tections normal vs edge cases"""
        base_dir = project_paths['data'] / 'images'
        results_by_cat = detector.detect_on_dataset_by_category(str(base_dir))
        
        # Calculer taux de d√©tection
        def detection_rate(results):
            if not results:
                return 0
            return sum(r['num_detections'] for r in results) / len(results)
        
        normal_rate = detection_rate(results_by_cat.get('normal', []))
        edge_rate = detection_rate(results_by_cat.get('edge_cases', []))
        
        # Edge cases devraient avoir moins de d√©tections (d√©gradation)
        if 'edge_cases' in results_by_cat and normal_rate > 0:
            degradation = (normal_rate - edge_rate) / normal_rate * 100
            
            print(f"\n   üìä D√©tections par image :")
            print(f"      Normal     : {normal_rate:.2f}")
            print(f"      Edge cases : {edge_rate:.2f}")
            print(f"      D√©gradation: {degradation:.1f}%")
            
            # On accepte jusqu'√† 50% de d√©gradation sur edge cases
            assert degradation <= 50, \
                f"D√©gradation trop importante : {degradation:.1f}%"


class TestResultsSaving:
    """Tests de sauvegarde des r√©sultats"""
    
    @pytest.fixture(scope="class")
    def detector(self):
        return YOLODetector()
    
    def test_save_results_creates_file(self, detector, dataset_normal_path, tmp_path):
        """V√©rifie que save_results() cr√©e un fichier"""
        results = detector.detect_on_dataset(dataset_normal_path, verbose=False)
        
        output_file = tmp_path / "test_results.json"
        detector.save_results(results, str(output_file))
        
        # Fichier cr√©√©
        assert output_file.exists(), "Fichier de r√©sultats non cr√©√©"
        
        # Fichier non vide
        assert output_file.stat().st_size > 0, "Fichier de r√©sultats vide"
    
    def test_save_results_json_format(self, detector, dataset_normal_path, tmp_path):
        """V√©rifie le format JSON des r√©sultats sauvegard√©s"""
        results = detector.detect_on_dataset(dataset_normal_path, verbose=False)
        
        output_file = tmp_path / "test_results.json"
        detector.save_results(results, str(output_file))
        
        # Charger et v√©rifier le JSON
        with open(output_file) as f:
            data = json.load(f)
        
        # Cl√©s requises
        assert 'model' in data, "Cl√© 'model' manquante"
        assert 'total_images' in data, "Cl√© 'total_images' manquante"
        assert 'total_detections' in data, "Cl√© 'total_detections' manquante"
        assert 'avg_inference_time' in data, "Cl√© 'avg_inference_time' manquante"
        assert 'results' in data, "Cl√© 'results' manquante"
        
        # Valeurs coh√©rentes
        assert data['total_images'] == len(results)
        assert len(data['results']) == len(results)
        
        print(f"\n   ‚úÖ JSON valide avec {data['total_images']} images")